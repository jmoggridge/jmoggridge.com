---
title: Scrape a table from Wikipedia using R with the rvest package
subtitle: ...without knowing anything about xml or css
author: Jason A. Moggridge
date: '2022-08-26'
slug: []
excerpt: "Easy web scraping with R"
categories:
  - Coding
tags:
  - R
  - Tutorial
---


We want to download and parse the table on this page: "https://en.wikipedia.org/wiki/List_of_academic_publishers_by_preprint_policy"  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=F, warning=F)
```

We'll use the `tidyverse` and `rvest` packages to make this easier for us.

```{r}
# install.packages(c('tidyverse', 'rvest'))
library(tidyverse)
library(rvest)

# This is our url
my_url <- 
  "https://en.wikipedia.org/wiki/List_of_academic_publishers_by_preprint_policy"
```

Now to get the table: we use `read_html()` to get the entire html content; `html_node()` extracts the first table; then `html_table()` parses that element into an R data.frame that is easy to work with.

```{r}
my_table <- 
  my_url |> 
  rvest::read_html() |>
  rvest::html_node('table') |> 
  rvest::html_table()

my_table
```

And we're done! Just kidding, the parser had a bit of trouble with the double header rows, where the three columns `Location`, `Version`, and `License` were grouped under `Restriction`. Currently, those three columns are named `Restriction`;  that's not good - we need unique names to differentiate them.  

To fix this, we'll just use the first row of the table to set the column names and then drop the first row from the table with `slice()`.

```{r}
fixed_table <- 
  my_table |> 
  rlang::set_names(my_table[1,]) |>
  dplyr::slice(-1)
```

Finally, I don't need the `source` column since I didn't scrape the links for those and I'm not too worried about verifying these data anyway. I'll make the names lower snake-case with `janitor::clean_names()` since I'm OCD.

```{r}
preprint_policy <- 
  fixed_table |> 
  select(-Source) |> 
  janitor::clean_names() |> 
  print()
```

This looks good so I'll save the data as a comma-separated values (.csv) for later use.

```{r eval=FALSE}
readr::write_csv(preprint_policy, 'data/preprint_policy.csv')
```

